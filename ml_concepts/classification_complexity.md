### üåü Classifier Comparison Table (with Time & Space Complexity)

Classifiers **sorted by their training time complexity from lowest to highest** (minimum O(n x d) is needed for storing input data):

| Time Complexity (Train)  | Space Complexity        | Classifier                             | Type                  | `sklearn` / Lib Name                   |
|--------------------------|--------------------------|----------------------------------------|-----------------------|----------------------------------------|
| O(n √ó d)                | O(d)                     | Naive Bayes                            | Probabilistic         | `MultinomialNB()`                      |
| O(n √ó d)                | O(d)                     | Logistic Regression                    | Linear Model          | `LogisticRegression()`                 |
| O(k √ó n √ó d)            | O(d)                     | SGDClassifier                          | Linear Model          | `SGDClassifier()`                      |
| O(n √ó d)                | O(n √ó d)                 | KNN Classifier                         | Instance-Based        | `KNeighborsClassifier()`               |
| O(n √ó d √ó log n)        | O(n)                     | Decision Tree                          | Tree-Based            | `DecisionTreeClassifier()`             |
| O(n √ó d¬≤)               | O(d¬≤)                    | Quadratic Discriminant Analysis (QDA)  | Probabilistic         | `QuadraticDiscriminantAnalysis()`      |
| O(t √ó n √ó d)            | O(t √ó d)                 | XGBoost                                | Ensemble (Boost)      | `XGBClassifier()`                      |
| O(t √ó n √ó d)            | O(t √ó d)                 | CatBoost                               | Ensemble (Boost)      | `CatBoostClassifier()`                 |
| O(t √ó n √ó log d)        | O(t √ó d)                 | LightGBM                               | Ensemble (Boost)      | `LGBMClassifier()`                     |
| O(t √ó n √ó log n)        | O(t √ó n)                 | Extra Trees                            | Ensemble (Tree-Based) | `ExtraTreesClassifier()`               |
| O(t √ó n √ó d √ó log n)    | O(t √ó n)                 | Random Forest                          | Ensemble (Tree-Based) | `RandomForestClassifier()`             |
| O(e √ó n √ó d √ó h)        | O(h √ó d)                 | MLPClassifier (Neural Net)             | Neural Network        | `MLPClassifier()`                      |
| O(n¬≤ √ó d)               | O(n¬≤)                    | SVC (RBF Kernel)                       | Kernel Method         | `SVC(kernel='rbf')`                    |
| O(n¬≥)                   | O(n¬≤)                    | Gaussian Process Classifier            | Probabilistic         | `GaussianProcessClassifier()`          |
| Depends on base models  | Sum of base models       | Voting Classifier                      | Ensemble (Voting)     | `VotingClassifier()`                   |
| Depends on all models   | Sum of all models        | Stacking Classifier                    | Ensemble (Stacking)   | `StackingClassifier()`                 |

---

### üìò Parameter Definitions

| Symbol | Meaning |
|--------|---------|
| **n** | Number of training samples |
| **d** | Number of features (dimensionality of input) |
| **k** | Number of iterations (epochs) for SGD |
| **t** | Number of trees or estimators |
| **e** | Number of training epochs (for neural nets) |
| **h** | Number of hidden units in the neural network |

---

### üïê Notes on Complexity

- The listed **time complexity** is for **training** unless otherwise noted.
- For most models, **inference time** is **much faster** than training:
  - For example, **KNN** is fast to train (no training!) but **slow to predict**: \( O(n √ó d) \)
  - In contrast, **tree-based models** like Random Forest or XGBoost have **fast inference** (typically \( O(\text{depth}) \))
- Models like **SGDClassifier** can support **online learning**, making them very efficient on streaming data.

