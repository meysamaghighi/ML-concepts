## ðŸ“Œ Dimensionality Reduction

| Model                  | Description                                           | Pros                                               | Cons                                              | Example Code                                    | Notes                             |
|------------------------|-------------------------------------------------------|----------------------------------------------------|---------------------------------------------------|--------------------------------------------------|-----------------------------------|
| PCA                    | Linear projection maximizing variance                | Fast, interpretable                                | Linear only                                       | `PCA()` (sklearn)                                | Use with dense data               |
| Truncated SVD          | PCA for sparse data                                  | Works with sparse matrix (TF-IDF)                  | Not good for dense data                           | `TruncatedSVD()` (sklearn)                      | Use in NLP                        |
| t-SNE                  | Visualizes high-dim structure                        | Preserves local structure                          | Not scalable, non-parametric                      | `TSNE()` (sklearn.manifold)                     | For visualization only            |
| UMAP                   | Fast and structure-preserving                        | Better than t-SNE in many cases                    | Still sensitive to parameters                     | `UMAP()` (umap-learn)                           | Great for clusters                |
| Isomap                 | Nonlinear manifold learning                          | Captures global structure                          | Sensitive to noise                                | `Isomap()` (sklearn.manifold)                   | Use for smooth manifolds          |
| LLE                    | Local manifold learning                              | Preserves local geometry                           | Can break with noisy data                         | `LocallyLinearEmbedding()` (sklearn.manifold)    | Good for local structure          |
| Spectral Embedding     | Uses graph Laplacians                                | Flexible, handles complex shapes                   | Memory-intensive                                  | `SpectralEmbedding()` (sklearn.manifold)         | Similar to Spectral Clustering    |
| NMF                    | Decomposes into non-negative parts                   | Useful for sparse text/images                      | Only works on positive data                       | `NMF()` (sklearn.decomposition)                 | Use with image/text features      |
| Factor Analysis        | Finds latent factors                                | Useful in psychology/social sciences               | Less commonly used in ML                          | `FactorAnalysis()` (sklearn.decomposition)      | Linear technique                  |
| Autoencoder (NN)       | Neural network for compression                       | Powerful, learns non-linear mappings               | Needs tuning + more data                          | `Sequential(..., Dense(...))` (Keras)           | Requires deep learning lib        |
